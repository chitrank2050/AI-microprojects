{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eda0e43",
   "metadata": {},
   "source": [
    "# Discrete Math & Statistics for Machine Learning\n",
    "\n",
    "Discrete mathematics and statistics provide the structure behind:\n",
    "\n",
    "- Combinatorics (counting & probability foundations)\n",
    "- Statistics (mean, variance, covariance)\n",
    "- Hypothesis testing\n",
    "- Information theory (entropy, cross-entropy)\n",
    "\n",
    "These concepts directly power:\n",
    "- Naive Bayes\n",
    "- Decision trees\n",
    "- Cross-entropy loss\n",
    "- Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1f232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da16f304",
   "metadata": {},
   "source": [
    "# 1. Combinatorics\n",
    "\n",
    "Combinatorics helps us count possibilities.\n",
    "\n",
    "Factorial:\n",
    "n! = n × (n-1) × ... × 1\n",
    "\n",
    "Used in probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca52daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5! = 120\n"
     ]
    }
   ],
   "source": [
    "def factorial_manual(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    result = 1\n",
    "    for i in range(1, n+1):\n",
    "        result *= i\n",
    "    return result\n",
    "\n",
    "print(\"5! =\", factorial_manual(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb974d",
   "metadata": {},
   "source": [
    "## Permutations\n",
    "\n",
    "Number of ways to arrange r objects from n:\n",
    "\n",
    "P(n, r) = n! / (n-r)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22cac855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(5,2) = 20\n"
     ]
    }
   ],
   "source": [
    "from math import factorial, log2\n",
    "\n",
    "def permutations(n, r):\n",
    "    return factorial(n) // factorial(n-r)\n",
    "\n",
    "print(\"P(5,2) =\", permutations(5,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee2355",
   "metadata": {},
   "source": [
    "## Combinations\n",
    "\n",
    "Number of ways to choose r objects from n:\n",
    "\n",
    "C(n, r) = n! / (r! (n-r)!)\n",
    "\n",
    "Used in binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdcf9542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C(5,2) = 10\n"
     ]
    }
   ],
   "source": [
    "def combinations(n, r):\n",
    "    return factorial(n) // (factorial(r) * factorial(n-r))\n",
    "\n",
    "print(\"C(5,2) =\", combinations(5,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef62300",
   "metadata": {},
   "source": [
    "# 2. Binomial Distribution\n",
    "\n",
    "Probability of exactly k successes in n trials:\n",
    "\n",
    "P(X=k) = C(n,k) p^k (1-p)^(n-k)\n",
    "\n",
    "Used in:\n",
    "- Binary classification\n",
    "- Bernoulli processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "702427d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(3 successes in 5 trials, p=0.5): 0.3125\n"
     ]
    }
   ],
   "source": [
    "def binomial_probability(n, k, p):\n",
    "    return combinations(n, k) * (p**k) * ((1-p)**(n-k))\n",
    "\n",
    "print(\"P(3 successes in 5 trials, p=0.5):\", binomial_probability(5,3,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c42cf",
   "metadata": {},
   "source": [
    "# 3. Descriptive Statistics\n",
    "\n",
    "Statistics summarize data.\n",
    "\n",
    "Key measures:\n",
    "- Mean\n",
    "- Variance\n",
    "- Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad0619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.02999326587781465\n",
      "Variance: 0.9824353249435221\n",
      "Std Dev: 0.9911787552926677\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randn(1000)\n",
    "\n",
    "mean = np.mean(data)\n",
    "variance = np.var(data)\n",
    "std = np.std(data)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Variance:\", variance)\n",
    "print(\"Std Dev:\", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd005783",
   "metadata": {},
   "source": [
    "# 4. Covariance\n",
    "\n",
    "Covariance measures how two variables move together.\n",
    "\n",
    "Cov(X,Y) = E[(X - μx)(Y - μy)]\n",
    "\n",
    "Used in:\n",
    "- PCA\n",
    "- Feature relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58d64d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:\n",
      " [[0.9977 1.9986]\n",
      " [1.9986 4.283 ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(1000)\n",
    "y = 2*x + np.random.randn(1000)*0.5\n",
    "\n",
    "cov_matrix = np.cov(x, y)\n",
    "\n",
    "print(\"Covariance matrix:\\n\", cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b6d32a",
   "metadata": {},
   "source": [
    "# 5. Hypothesis Testing (Intuition)\n",
    "\n",
    "Null hypothesis (H₀):\n",
    "No effect / no difference.\n",
    "\n",
    "Alternative hypothesis (H₁):\n",
    "There is an effect.\n",
    "\n",
    "We compute a test statistic and compare against a threshold.\n",
    "\n",
    "Example: One-sample z-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4397abd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 9.343825080808616\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.normal(loc=1.0, scale=1.0, size=100)\n",
    "\n",
    "population_mean = 0\n",
    "sample_mean = np.mean(sample)\n",
    "sample_std = np.std(sample)\n",
    "\n",
    "z_score = (sample_mean - population_mean) / (sample_std / np.sqrt(len(sample)))\n",
    "\n",
    "print(\"Z-score:\", z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec39bee",
   "metadata": {},
   "source": [
    "If |z| is large, we reject the null hypothesis.\n",
    "\n",
    "In ML:\n",
    "Hypothesis testing helps evaluate models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c297b",
   "metadata": {},
   "source": [
    "# 6. Information Theory\n",
    "\n",
    "Information theory is foundational for:\n",
    "\n",
    "- Decision Trees\n",
    "- Cross-Entropy Loss\n",
    "- KL Divergence\n",
    "- Language Models\n",
    "\n",
    "The key concept is entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d384535",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "Entropy measures uncertainty:\n",
    "\n",
    "H(X) = - Σ p(x) log₂ p(x)\n",
    "\n",
    "High entropy → high uncertainty\n",
    "Low entropy → predictable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1da50d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (fair coin): 1.0\n",
      "Entropy (biased coin): 0.4689955935892812\n"
     ]
    }
   ],
   "source": [
    "def entropy(probabilities):\n",
    "    return -sum(p * log2(p) for p in probabilities if p > 0)\n",
    "\n",
    "probs = [0.5, 0.5]\n",
    "print(\"Entropy (fair coin):\", entropy(probs))\n",
    "\n",
    "probs = [0.9, 0.1]\n",
    "print(\"Entropy (biased coin):\", entropy(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2c0a5",
   "metadata": {},
   "source": [
    "# 7. Cross Entropy\n",
    "\n",
    "Used as loss function in classification.\n",
    "\n",
    "Cross-Entropy:\n",
    "\n",
    "H(p, q) = - Σ p(x) log q(x)\n",
    "\n",
    "In neural networks:\n",
    "- p = true labels\n",
    "- q = predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c1ecfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy: 0.22314355006420974\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(true, pred):\n",
    "    return -np.sum(true * np.log(pred + 1e-9))\n",
    "\n",
    "true = np.array([1, 0])\n",
    "pred = np.array([0.8, 0.2])\n",
    "\n",
    "print(\"Cross-Entropy:\", cross_entropy(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20923cc7",
   "metadata": {},
   "source": [
    "# 8. KL Divergence\n",
    "\n",
    "Measures difference between two distributions:\n",
    "\n",
    "KL(p || q) = Σ p(x) log(p(x)/q(x))\n",
    "\n",
    "Used in:\n",
    "- Variational Autoencoders\n",
    "- Regularization\n",
    "- Probabilistic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4b225c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: 0.029049405545331364\n"
     ]
    }
   ],
   "source": [
    "def kl_divergence(p, q):\n",
    "    return sum(p[i] * log2(p[i]/q[i]) for i in range(len(p)) if p[i] > 0)\n",
    "\n",
    "p = [0.6, 0.4]\n",
    "q = [0.5, 0.5]\n",
    "\n",
    "print(\"KL Divergence:\", kl_divergence(p, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e62b46",
   "metadata": {},
   "source": [
    "# Discrete Math → Machine Learning\n",
    "\n",
    "Combinatorics → Binomial models  \n",
    "Statistics → Data summarization  \n",
    "Covariance → PCA  \n",
    "Entropy → Decision Trees  \n",
    "Cross-Entropy → Neural Network Loss  \n",
    "KL Divergence → Modern probabilistic models  \n",
    "\n",
    "Discrete mathematics provides structure for reasoning about data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-microprojects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
